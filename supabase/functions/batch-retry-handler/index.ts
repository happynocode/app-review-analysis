import { createClient } from 'npm:@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
}

enum ErrorType {
  TIMEOUT = 'timeout',
  API_LIMIT = 'api_limit',
  MEMORY_LIMIT = 'memory_limit',
  NETWORK_ERROR = 'network_error',
  DATA_ERROR = 'data_error',
  UNKNOWN = 'unknown'
}

interface RetryConfig {
  maxRetries: number
  baseDelay: number        // åŸºç¡€å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
  maxDelay: number         // æœ€å¤§å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
  exponentialFactor: number // æŒ‡æ•°å› å­
  jitterEnabled: boolean   // æ˜¯å¦å¯ç”¨æŠ–åŠ¨
}

interface FailedTask {
  id: string
  report_id: string
  batch_id: string
  retry_count: number
  max_retries: number
  error_details: any
  last_error: string
  failed_at: string
}

interface RetryRequest {
  taskId?: string          // é‡è¯•ç‰¹å®šä»»åŠ¡
  reportId?: string        // é‡è¯•æŠ¥å‘Šçš„æ‰€æœ‰å¤±è´¥ä»»åŠ¡
  batchId?: string         // é‡è¯•æ‰¹æ¬¡çš„æ‰€æœ‰å¤±è´¥ä»»åŠ¡
  errorType?: ErrorType    // é‡è¯•ç‰¹å®šé”™è¯¯ç±»å‹çš„ä»»åŠ¡
  forceRetry?: boolean     // å¼ºåˆ¶é‡è¯•ï¼ˆå³ä½¿è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰
  customConfig?: Partial<RetryConfig>
}

// é»˜è®¤é‡è¯•é…ç½®
const DEFAULT_RETRY_CONFIG: RetryConfig = {
  maxRetries: 3,
  baseDelay: 2000,         // 2ç§’
  maxDelay: 300000,        // 5åˆ†é’Ÿ
  exponentialFactor: 2,
  jitterEnabled: true
}

// é’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹çš„é‡è¯•é…ç½®
const ERROR_TYPE_CONFIGS: Record<ErrorType, Partial<RetryConfig>> = {
  [ErrorType.TIMEOUT]: {
    maxRetries: 2,
    baseDelay: 5000,       // è¶…æ—¶é”™è¯¯å»¶è¿Ÿæ›´é•¿
    exponentialFactor: 1.5
  },
  [ErrorType.API_LIMIT]: {
    maxRetries: 5,
    baseDelay: 60000,      // APIé™åˆ¶å»¶è¿Ÿ1åˆ†é’Ÿ
    exponentialFactor: 1.2
  },
  [ErrorType.MEMORY_LIMIT]: {
    maxRetries: 1,         // å†…å­˜é™åˆ¶é‡è¯•æ¬¡æ•°å°‘
    baseDelay: 10000,
    exponentialFactor: 2
  },
  [ErrorType.NETWORK_ERROR]: {
    maxRetries: 4,
    baseDelay: 1000,
    exponentialFactor: 2
  },
  [ErrorType.DATA_ERROR]: {
    maxRetries: 1,         // æ•°æ®é”™è¯¯é€šå¸¸æ— æ³•é€šè¿‡é‡è¯•è§£å†³
    baseDelay: 5000,
    exponentialFactor: 1
  },
  [ErrorType.UNKNOWN]: {
    maxRetries: 2,
    baseDelay: 3000,
    exponentialFactor: 1.5
  }
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    )

    const { 
      taskId, 
      reportId, 
      batchId, 
      errorType, 
      forceRetry, 
      customConfig 
    }: RetryRequest = await req.json()

    console.log('ğŸ”„ Batch Retry Handler: Processing retry request...')

    let failedTasks: FailedTask[] = []

    // æŸ¥æ‰¾éœ€è¦é‡è¯•çš„ä»»åŠ¡
    if (taskId) {
      // é‡è¯•ç‰¹å®šä»»åŠ¡
      const { data: task, error } = await supabaseClient
        .from('processing_queue')
        .select('*')
        .eq('id', taskId)
        .eq('status', 'failed')
        .single()

      if (error || !task) {
        return new Response(
          JSON.stringify({ error: 'Failed task not found' }),
          { 
            status: 404, 
            headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
          }
        )
      }

      failedTasks = [task]
    } else {
      // æ„å»ºæŸ¥è¯¢æ¡ä»¶
      let query = supabaseClient
        .from('processing_queue')
        .select('*')
        .eq('status', 'failed')

      if (reportId) query = query.eq('report_id', reportId)
      if (batchId) query = query.eq('batch_id', batchId)
      
      if (!forceRetry) {
        query = query.lt('retry_count', supabaseClient.raw('max_retries'))
      }

      const { data: tasks, error } = await query
        .order('priority', { ascending: false })
        .limit(50) // é™åˆ¶æ‰¹é‡å¤„ç†æ•°é‡

      if (error) {
        throw new Error(`Failed to fetch failed tasks: ${error.message}`)
      }

      failedTasks = tasks || []

      // æŒ‰é”™è¯¯ç±»å‹è¿‡æ»¤
      if (errorType) {
        failedTasks = failedTasks.filter(task => 
          classifyError(task.error_details) === errorType
        )
      }
    }

    if (failedTasks.length === 0) {
      return new Response(
        JSON.stringify({ 
          success: true, 
          message: 'No eligible failed tasks found for retry',
          retriedTasks: 0
        }),
        { 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    console.log(`ğŸš€ Found ${failedTasks.length} failed tasks to retry`)

    const retryResults = []

    // å¤„ç†æ¯ä¸ªå¤±è´¥çš„ä»»åŠ¡
    for (const task of failedTasks) {
      try {
        const errorType = classifyError(task.error_details)
        const retryConfig = getRetryConfig(errorType, customConfig)
        
        // æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡è¯•
        if (!forceRetry && task.retry_count >= task.max_retries) {
          console.log(`â­ï¸ Task ${task.id} has exceeded max retries, skipping`)
          continue
        }

        // è®¡ç®—å»¶è¿Ÿæ—¶é—´
        const delay = calculateDelay(task.retry_count, retryConfig)
        
        console.log(`â° Scheduling retry for task ${task.id} with ${delay}ms delay`)

        // è°ƒåº¦é‡è¯•ï¼ˆç«‹å³æ›´æ–°çŠ¶æ€ï¼Œå»¶è¿Ÿæ‰§è¡Œï¼‰
        const retryResult = await scheduleRetry(task, delay, supabaseClient)
        retryResults.push(retryResult)

      } catch (error) {
        console.error(`âŒ Failed to schedule retry for task ${task.id}:`, error)
        retryResults.push({
          taskId: task.id,
          success: false,
          error: error.message
        })
      }
    }

    // è®°å½•é‡è¯•ç»Ÿè®¡
    await logRetryMetrics(failedTasks.length, retryResults, supabaseClient)

    const successfulRetries = retryResults.filter(r => r.success).length

    return new Response(
      JSON.stringify({
        success: true,
        message: `Scheduled ${successfulRetries} task retries`,
        totalTasks: failedTasks.length,
        scheduledRetries: successfulRetries,
        retryResults: retryResults,
        timestamp: new Date().toISOString()
      }),
      { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('Error in batch-retry-handler:', error)
    return new Response(
      JSON.stringify({ 
        error: 'Retry scheduling failed',
        details: error.message 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})

// åˆ†ç±»é”™è¯¯ç±»å‹
function classifyError(errorDetails: any): ErrorType {
  if (!errorDetails) return ErrorType.UNKNOWN

  const errorString = JSON.stringify(errorDetails).toLowerCase()

  if (errorString.includes('timeout') || errorString.includes('time out')) {
    return ErrorType.TIMEOUT
  }
  if (errorString.includes('rate limit') || errorString.includes('api limit')) {
    return ErrorType.API_LIMIT
  }
  if (errorString.includes('memory') || errorString.includes('heap')) {
    return ErrorType.MEMORY_LIMIT
  }
  if (errorString.includes('network') || errorString.includes('connection')) {
    return ErrorType.NETWORK_ERROR
  }
  if (errorString.includes('invalid data') || errorString.includes('parse error')) {
    return ErrorType.DATA_ERROR
  }

  return ErrorType.UNKNOWN
}

// è·å–é‡è¯•é…ç½®
function getRetryConfig(errorType: ErrorType, customConfig?: Partial<RetryConfig>): RetryConfig {
  const baseConfig = { ...DEFAULT_RETRY_CONFIG }
  const errorConfig = ERROR_TYPE_CONFIGS[errorType] || {}
  const finalConfig = { ...baseConfig, ...errorConfig, ...customConfig }
  return finalConfig
}

// è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ + æŠ–åŠ¨ï¼‰
function calculateDelay(retryCount: number, config: RetryConfig): number {
  let delay = config.baseDelay * Math.pow(config.exponentialFactor, retryCount)
  
  // é™åˆ¶æœ€å¤§å»¶è¿Ÿ
  delay = Math.min(delay, config.maxDelay)
  
  // æ·»åŠ æŠ–åŠ¨ä»¥é¿å…é›·ç¾¤æ•ˆåº”
  if (config.jitterEnabled) {
    const jitter = delay * 0.1 * Math.random() // 10%çš„éšæœºæŠ–åŠ¨
    delay += jitter
  }
  
  return Math.round(delay)
}

// è°ƒåº¦é‡è¯•
async function scheduleRetry(
  task: FailedTask,
  delay: number,
  supabaseClient: any
): Promise<any> {
  
  // æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæ’é˜Ÿï¼Œå¢åŠ é‡è¯•è®¡æ•°
  const { error: updateError } = await supabaseClient
    .from('processing_queue')
    .update({
      status: 'queued',
      retry_count: task.retry_count + 1,
      scheduled_at: new Date(Date.now() + delay).toISOString(),
      error_details: null // æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
    })
    .eq('id', task.id)

  if (updateError) {
    throw new Error(`Failed to update task status: ${updateError.message}`)
  }

  // å»¶è¿Ÿåè°ƒç”¨å®é™…å¤„ç†å‡½æ•°
  setTimeout(async () => {
    try {
      console.log(`ğŸš€ Executing delayed retry for task ${task.id}`)
      
      // è°ƒç”¨process-analysis-batch-v2è¿›è¡Œå®é™…å¤„ç†
      const response = await fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/process-analysis-batch-v2`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')}`
        },
        body: JSON.stringify({
          queueId: task.id,
          forceRetry: true
        })
      })

      if (!response.ok) {
        throw new Error(`Process batch failed: ${response.statusText}`)
      }

      console.log(`âœ… Successfully triggered retry for task ${task.id}`)
    } catch (error) {
      console.error(`âŒ Retry execution failed for task ${task.id}:`, error)
      
      // æ ‡è®°ä¸ºæ°¸ä¹…å¤±è´¥
      await supabaseClient
        .from('processing_queue')
        .update({
          status: 'failed',
          error_details: { 
            ...task.error_details, 
            retry_failed: true, 
            retry_error: error.message 
          }
        })
        .eq('id', task.id)
    }
  }, delay)

  return {
    taskId: task.id,
    success: true,
    delay: delay,
    scheduledAt: new Date(Date.now() + delay).toISOString()
  }
}

// è®°å½•é‡è¯•æŒ‡æ ‡
async function logRetryMetrics(
  totalTasks: number,
  retryResults: any[],
  supabaseClient: any
): Promise<void> {
  try {
    const successfulRetries = retryResults.filter(r => r.success).length
    const failedRetries = retryResults.filter(r => !r.success).length

    // è®°å½•ç³»ç»ŸæŒ‡æ ‡
    await supabaseClient
      .from('system_metrics')
      .insert([
        {
          metric_name: 'retry_tasks_total',
          metric_value: totalTasks,
          metric_unit: 'count',
          tags: { component: 'batch-retry-handler' }
        },
        {
          metric_name: 'retry_tasks_successful',
          metric_value: successfulRetries,
          metric_unit: 'count',
          tags: { component: 'batch-retry-handler' }
        },
        {
          metric_name: 'retry_tasks_failed',
          metric_value: failedRetries,
          metric_unit: 'count',
          tags: { component: 'batch-retry-handler' }
        }
      ])

    console.log(`ğŸ“Š Logged retry metrics: ${successfulRetries}/${totalTasks} successful`)
  } catch (error) {
    console.error('Failed to log retry metrics:', error)
  }
} 