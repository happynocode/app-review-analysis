import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { createClient } from 'jsr:@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
}

interface ProcessBatchRequestV2 {
  reportId: string           // Report ID to process
  batchIndex?: number        // Specific batch index to process
  tasks?: any[]             // Direct task data from start-analysis-v2
  enableChainProcessing?: boolean  // Deprecated - now handled by database triggers
  forceRetry?: boolean      // Force retry failed tasks
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    )

    const { reportId, batchIndex, tasks, forceRetry }: ProcessBatchRequestV2 = await req.json()

    if (!reportId) {
      return new Response(
        JSON.stringify({ error: 'reportId is required' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    let tasksToProcess: any[] = []

    if (tasks && tasks.length > 0) {
      // Direct task processing (from start-analysis-v2)
      console.log(`ğŸ¯ Processing ${tasks.length} direct tasks for report ${reportId}`)
      tasksToProcess = tasks
    } else if (batchIndex !== undefined) {
      // Process specific batch index
      console.log(`ğŸ¯ Processing batch ${batchIndex} for report ${reportId}`)
      const { data: batchTasks, error: tasksError } = await supabaseClient
        .from('analysis_tasks')
        .select('*')
        .eq('report_id', reportId)
        .eq('batch_index', batchIndex)
        .in('status', ['pending', ...(forceRetry ? ['failed'] : [])])
        .order('priority', { ascending: false })

      if (tasksError) {
        throw new Error(`Failed to fetch batch tasks: ${tasksError.message}`)
      }

      tasksToProcess = batchTasks || []
    } else {
      // Find next pending tasks for this report (up to 4 tasks)
      console.log(`ğŸ” Looking for next pending tasks for report ${reportId}...`)
      const { data: pendingTasks, error: tasksError } = await supabaseClient
        .from('analysis_tasks')
        .select('*')
        .eq('report_id', reportId)
        .in('status', ['pending', ...(forceRetry ? ['failed'] : [])])
        .order('batch_index', { ascending: true })
        .order('priority', { ascending: false })
        .limit(4) // Process up to 4 tasks per call

      if (tasksError) {
        throw new Error(`Failed to fetch pending tasks: ${tasksError.message}`)
      }

      tasksToProcess = pendingTasks || []
    }

    if (tasksToProcess.length === 0) {
      console.log(`â„¹ï¸ No tasks to process for report ${reportId}`)
      
      return new Response(
        JSON.stringify({ 
          success: true, 
          message: 'No tasks to process',
          processed: 0
        }),
        { 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    console.log(`ğŸš€ Processing ${tasksToProcess.length} analysis tasks`)

    // Process all tasks in parallel using Promise.allSettled for better error handling
    const processingPromises = tasksToProcess.map(task => 
      processAnalysisTaskV2(task, supabaseClient)
    )

    const results = await Promise.allSettled(processingPromises)
    const successCount = results.filter(r => r.status === 'fulfilled').length
    const failureCount = results.length - successCount

    console.log(`ğŸ“Š Batch processing complete: ${successCount} success, ${failureCount} failed`)

    // é“¾å¼è°ƒç”¨é€»è¾‘å·²ç§»é™¤ - ç°åœ¨ç”±æ•°æ®åº“è§¦å‘å™¨è‡ªåŠ¨å¤„ç†åç»­æ‰¹æ¬¡

    return new Response(
      JSON.stringify({ 
        success: true, 
        message: `Processed ${tasksToProcess.length} analysis tasks`,
        processed: successCount,
        failed: failureCount,
        taskIds: tasksToProcess.map(t => t.id)
      }),
      { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('Error in process-analysis-batch-v2:', error)
    return new Response(
      JSON.stringify({ 
        error: 'Internal server error',
        details: error.message 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})

async function processAnalysisTaskV2(task: any, supabaseClient: any) {
  const startTime = Date.now()
  let taskStatusUpdated = false

  try {
    console.log(`ğŸ”„ Processing analysis task ${task.id} (themes analysis, batch ${task.batch_index})`)

    // Update task status to processing with error handling
    const { error: statusError } = await supabaseClient
      .from('analysis_tasks')
      .update({
        status: 'processing',
        updated_at: new Date().toISOString()
      })
      .eq('id', task.id)

    if (statusError) {
      throw new Error(`Failed to update task status to processing: ${statusError.message}`)
    }

    taskStatusUpdated = true

    // Get app name from report
    const { data: report, error: reportError } = await supabaseClient
      .from('reports')
      .select('app_name')
      .eq('id', task.report_id)
      .single()

    if (reportError || !report) {
      throw new Error('Failed to fetch report information')
    }

    // Perform themes analysis with Gemini and heartbeat updates
    console.log(`ğŸ§  Analyzing themes for batch ${task.batch_index} with Gemini...`)

    // è®¾ç½®å¿ƒè·³æœºåˆ¶ï¼Œæ¯2åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡ä»»åŠ¡çŠ¶æ€
    const heartbeatInterval = setInterval(async () => {
      try {
        await supabaseClient
          .from('analysis_tasks')
          .update({ updated_at: new Date().toISOString() })
          .eq('id', task.id)
        console.log(`ğŸ’“ Heartbeat update for task ${task.id}`)
      } catch (heartbeatError) {
        console.warn(`âš ï¸ Heartbeat update failed for task ${task.id}:`, heartbeatError)
      }
    }, 120000) // 2åˆ†é’Ÿé—´éš”

    let analysisResult
    try {
      analysisResult = await analyzeThemesWithGemini(
        report.app_name,
        task.reviews_data,
        task.batch_index
      )

      // æ¸…é™¤å¿ƒè·³å®šæ—¶å™¨
      clearInterval(heartbeatInterval)
    } catch (analysisError) {
      // ç¡®ä¿æ¸…é™¤å¿ƒè·³å®šæ—¶å™¨
      clearInterval(heartbeatInterval)
      throw analysisError
    }

    // Save analysis results to task (åªå­˜å‚¨themes_data)
    const updateData = {
      status: 'completed',
      themes_data: analysisResult,
      updated_at: new Date().toISOString()
    }

    await supabaseClient
      .from('analysis_tasks')
      .update(updateData)
      .eq('id', task.id)

    const processingTime = Date.now() - startTime
    console.log(`âœ… Completed task ${task.id} (themes) in ${Math.round(processingTime / 1000)}s`)

    // Log success metric
    await logSystemMetric(supabaseClient, 'task_processing_time', processingTime / 1000, 'seconds', {
      task_id: task.id,
      report_id: task.report_id,
      analysis_type: 'themes',
      status: 'success'
    })

  } catch (error) {
    console.error(`âŒ Error processing task ${task.id}:`, error)

    // ç¡®ä¿ä»»åŠ¡çŠ¶æ€è¢«æ­£ç¡®æ›´æ–°ï¼Œå³ä½¿åœ¨é”™è¯¯æƒ…å†µä¸‹
    try {
      const failureStatus = taskStatusUpdated ? 'failed' : 'pending' // å¦‚æœçŠ¶æ€è¿˜æ²¡æ›´æ–°ä¸ºprocessingï¼Œå›æ»šåˆ°pending

      await supabaseClient
        .from('analysis_tasks')
        .update({
          status: failureStatus,
          error_message: error.message,
          updated_at: new Date().toISOString()
        })
        .eq('id', task.id)

      console.log(`ğŸ“ Task ${task.id} status updated to ${failureStatus} due to error`)
    } catch (updateError) {
      console.error(`âŒ Failed to update task status after error:`, updateError)
    }

    // Log failure metric
    await logSystemMetric(supabaseClient, 'task_processing_failures', 1, 'count', {
      task_id: task.id,
      report_id: task.report_id,
      analysis_type: 'themes',
      error: error.message,
      task_status_was_updated: taskStatusUpdated
    })

    throw error // Re-throw to be handled by Promise.allSettled
  }
}

// ç®€åŒ–çš„themesåˆ†æå‡½æ•°
async function analyzeThemesWithGemini(appName: string, reviews: any[], batchIndex: number) {
  const geminiApiKey = Deno.env.get('GEMINI_API_KEY')

  if (!geminiApiKey) {
    throw new Error('GEMINI_API_KEY environment variable is not set')
  }

  // æŒ‰å¹³å°åˆ†ç»„è¯„è®º
  const platformGroups = {
    reddit: reviews.filter(r => r.platform === 'reddit'),
    app_store: reviews.filter(r => r.platform === 'app_store'),
    google_play: reviews.filter(r => r.platform === 'google_play')
  }

  console.log(`ğŸ” Batch ${batchIndex} platform distribution: Reddit ${platformGroups.reddit.length}, App Store ${platformGroups.app_store.length}, Google Play ${platformGroups.google_play.length}`)

  const platformThemes = {
    reddit_themes: [],
    app_store_themes: [],
    google_play_themes: []
  }

  // åˆ†åˆ«åˆ†ææ¯ä¸ªå¹³å°çš„themes
  for (const [platform, platformReviews] of Object.entries(platformGroups)) {
    if (platformReviews.length === 0) {
      console.log(`â­ï¸ Skipping ${platform} - no reviews`)
      continue
    }

    console.log(`ğŸ§  Analyzing ${platform} themes (${platformReviews.length} reviews)...`)
    
    // Extract review text from review objects
    const reviewTexts = platformReviews
      .map(review => typeof review === 'string' ? review : review.review_text)
      .filter(text => text && text.trim().length > 10)
      .map(text => text.length > 400 ? text.substring(0, 400) + '...' : text)
      .slice(0, 50) // Smaller batches for better performance

    if (reviewTexts.length === 0) {
      console.log(`â­ï¸ Skipping ${platform} - no valid review texts`)
      continue
    }

    // é’ˆå¯¹ä¸åŒå¹³å°å®šåˆ¶åŒ–çš„prompt
    const platformSpecificPrompt = getPlatformSpecificPrompt(platform, appName, reviewTexts)

    try {
      const themes = await callGeminiAPI(platformSpecificPrompt)
      
      // ä¸ºæ¯ä¸ªthemeæ·»åŠ å¹³å°æ ‡è¯†
      const themesWithPlatform = themes.themes.map(theme => ({
        ...theme,
        platform: platform,
        source_platform: platform
      }))
      
      if (platform === 'reddit') {
        platformThemes.reddit_themes = themesWithPlatform
      } else if (platform === 'app_store') {
        platformThemes.app_store_themes = themesWithPlatform
      } else if (platform === 'google_play') {
        platformThemes.google_play_themes = themesWithPlatform
      }

      console.log(`âœ… ${platform} analysis complete: ${themesWithPlatform.length} themes found`)
      
    } catch (error) {
      console.error(`âŒ Error analyzing ${platform} themes:`, error)
      // ç»§ç»­å¤„ç†å…¶ä»–å¹³å°
    }
  }

  console.log(`ğŸ“Š Batch ${batchIndex} themes analysis complete: Reddit ${platformThemes.reddit_themes.length}, App Store ${platformThemes.app_store_themes.length}, Google Play ${platformThemes.google_play_themes.length}`)

  return platformThemes
}

// è·å–å¹³å°ç‰¹å®šçš„prompt
function getPlatformSpecificPrompt(platform: string, appName: string, reviewTexts: string[]): string {
  const platformNames = {
    reddit: 'Reddit',
    app_store: 'App Store',
    google_play: 'Google Play'
  }

  const platformContext = {
    reddit: 'Reddit discussions and community feedback',
    app_store: 'iOS App Store user reviews',
    google_play: 'Google Play Store user reviews'
  }

  const prompt = `You are an expert product analyst specializing in user feedback analysis. Your task is to identify the most important themes from ${platformContext[platform]} for "${appName}".

PLATFORM-SPECIFIC CONTEXT: 
This analysis focuses specifically on ${platformNames[platform]} feedback, which may have different characteristics and user perspectives compared to other platforms.

ANALYSIS GUIDELINES:
1. Focus on themes that appear across multiple reviews (not isolated complaints)
2. Prioritize actionable insights that could improve the product
3. Group similar feedback into coherent themes
4. Extract meaningful quotes that represent each theme
5. Provide specific, actionable suggestions for each theme
6. Consider the ${platformNames[platform]} user context and behavior patterns

QUALITY STANDARDS:
- Each theme should represent feedback from multiple users
- Theme titles should be clear and specific (2-5 words)
- Descriptions should explain the theme's impact and context (2-3 sentences)
- Quotes should be representative and authentic user voices
- Suggestions should be actionable and specific to the theme

${platformNames[platform].toUpperCase()} REVIEWS (${reviewTexts.length} reviews for ${appName}):
${reviewTexts.map((text, i) => `Review ${i + 1}: ${text}`).join('\n\n')}

CRITICAL OUTPUT REQUIREMENTS:
ğŸš¨ You MUST return ONLY valid JSON - no markdown, no explanatory text, no code blocks
ğŸš¨ Start your response with { and end with }
ğŸš¨ Do not include markdown code blocks or backticks
ğŸš¨ Do not add any text before or after the JSON

REQUIRED JSON FORMAT:
{
  "themes": [
    {
      "title": "Clear theme name (2-5 words)",
      "description": "Detailed explanation of what this theme represents and why it matters to users. Include the frequency and impact of this feedback.",
      "quotes": [
        "Exact quote from review that represents this theme",
        "Another representative quote showing this pattern"
      ],
      "suggestions": [
        "Specific actionable recommendation to address this theme",
        "Another concrete suggestion for improvement"
      ]
    }
  ]
}

VALIDATION RULES:
- Return 5-30 themes based on data quality and diversity
- Each theme title must be 2+ words (not single words like "json", "reddit")
- Ensure each theme has 2-3 representative quotes from actual reviews
- Make suggestions specific and actionable, not generic advice
- Consider this is ${platformNames[platform]} specific feedback when creating themes
- NO MARKDOWN FORMATTING - PURE JSON ONLY`

  return prompt
}

// Geminiæ¨¡å‹åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº (åŸºäºç”¨æˆ·åå¥½)
const GEMINI_MODELS = [
  'gemini-2.5-flash',
  'gemini-2.5-flash-preview-05-20',
  'gemini-2.5-flash-lite-preview-06-17',
  
  'gemini-2.0-flash',
  'gemini-2.0-flash-lite'
]

// æ¨¡å‹å¤±è´¥è·Ÿè¸ª
const modelFailureTracker = new Map<string, { count: number, lastFailure: number }>()

// ä¼°ç®—tokenæ•°é‡ (ç²—ç•¥ä¼°ç®—: 1 token â‰ˆ 4 characters)
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4)
}

// è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
function calculateBackoffDelay(attempt: number, baseDelay: number = 1000): number {
  const delay = baseDelay * Math.pow(2, attempt)
  const jitter = Math.random() * 0.1 * delay // 10% jitter
  return Math.min(delay + jitter, 60000) // æœ€å¤§60ç§’
}

// æ”¹è¿›çš„JSONæ¸…ç†å’Œä¿®å¤å‡½æ•°
function sanitizeJsonContent(content: string): string {
  let cleanContent = content.trim()

  // ç§»é™¤markdownæ ¼å¼
  if (cleanContent.startsWith('```json') && cleanContent.endsWith('```')) {
    cleanContent = cleanContent.slice(7, -3).trim()
  } else if (cleanContent.startsWith('```') && cleanContent.endsWith('```')) {
    cleanContent = cleanContent.slice(3, -3).trim()
  }

  // å¯»æ‰¾JSONå¯¹è±¡è¾¹ç•Œ
  const jsonStart = cleanContent.indexOf('{')
  let jsonEnd = cleanContent.lastIndexOf('}')

  if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
    cleanContent = cleanContent.slice(jsonStart, jsonEnd + 1)
  } else if (jsonStart !== -1) {
    // å¦‚æœæ‰¾åˆ°å¼€å§‹ä½†æ²¡æœ‰æ‰¾åˆ°ç»“æŸï¼Œå°è¯•ä¿®å¤
    cleanContent = cleanContent.slice(jsonStart)
    cleanContent = attemptJsonCompletion(cleanContent)
  }

  // ç§»é™¤å‰åç¼€æ–‡æœ¬
  cleanContent = cleanContent.replace(/^[^{]*/, '').replace(/[^}]*$/, '')

  return cleanContent
}

// å°è¯•å®Œæˆæˆªæ–­çš„JSON
function attemptJsonCompletion(jsonStr: string): string {
  let completed = jsonStr.trim()

  // è®¡ç®—æ‹¬å·å¹³è¡¡
  let braceCount = 0
  let bracketCount = 0
  let inString = false
  let escapeNext = false

  for (let i = 0; i < completed.length; i++) {
    const char = completed[i]

    if (escapeNext) {
      escapeNext = false
      continue
    }

    if (char === '\\') {
      escapeNext = true
      continue
    }

    if (char === '"' && !escapeNext) {
      inString = !inString
      continue
    }

    if (!inString) {
      if (char === '{') braceCount++
      else if (char === '}') braceCount--
      else if (char === '[') bracketCount++
      else if (char === ']') bracketCount--
    }
  }

  // å¦‚æœJSONåœ¨å­—ç¬¦ä¸²ä¸­é—´æˆªæ–­ï¼Œå°è¯•å…³é—­å­—ç¬¦ä¸²
  if (inString) {
    completed += '"'
  }

  // å…³é—­æœªé—­åˆçš„æ•°ç»„
  while (bracketCount > 0) {
    completed += ']'
    bracketCount--
  }

  // å…³é—­æœªé—­åˆçš„å¯¹è±¡
  while (braceCount > 0) {
    completed += '}'
    braceCount--
  }

  return completed
}

// ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
function fixCommonJsonIssues(jsonStr: string): string {
  let fixed = jsonStr

  // ä¿®å¤ç¼ºå¤±çš„é€—å·ï¼ˆåœ¨å¯¹è±¡å±æ€§ä¹‹é—´ï¼‰
  fixed = fixed.replace(/}(\s*)"/g, '},$1"')
  fixed = fixed.replace(/](\s*)"/g, '],$1"')
  fixed = fixed.replace(/"(\s*){/g, '",$1{')
  fixed = fixed.replace(/"(\s*)\[/g, '",$1[')

  // ä¿®å¤æ•°ç»„ä¸­ç¼ºå¤±çš„é€—å·
  fixed = fixed.replace(/}(\s*){/g, '},$1{')
  fixed = fixed.replace(/](\s*)\[/g, '],$1[')

  // ç§»é™¤å¤šä½™çš„é€—å·
  fixed = fixed.replace(/,(\s*[}\]])/g, '$1')
  fixed = fixed.replace(/,(\s*,)/g, ',')

  // ä¿®å¤å±æ€§åçš„å¼•å·
  fixed = fixed.replace(/([{,]\s*)(\w+):/g, '$1"$2":')

  // å°†å•å¼•å·æ”¹ä¸ºåŒå¼•å·
  fixed = fixed.replace(/:\s*'([^']*)'/g, ': "$1"')

  // ä¿®å¤è½¬ä¹‰çš„å•å¼•å·
  fixed = fixed.replace(/\\'/g, "'")

  return fixed
}

// è°ƒç”¨Gemini APIçš„é€šç”¨å‡½æ•°ï¼Œæ”¯æŒå¤šæ¨¡å‹å›é€€å’Œé€Ÿç‡é™åˆ¶å¤„ç†
async function callGeminiAPI(prompt: string) {
  const geminiApiKey = Deno.env.get('GEMINI_API_KEY')

  if (!geminiApiKey) {
    throw new Error('GEMINI_API_KEY environment variable is not set')
  }

  // æ£€æŸ¥è¾“å…¥tokenæ•°é‡
  const inputTokens = estimateTokens(prompt)
  console.log(`ğŸ“Š Estimated input tokens: ${inputTokens}`)

  if (inputTokens > 8000) { // ç•™ä¸€äº›ä½™é‡ç»™ç³»ç»Ÿæç¤º
    console.warn(`âš ï¸ Input tokens (${inputTokens}) approaching limit, consider reducing input size`)
  }

  let lastError: Error | null = null
  let globalAttempt = 0

  // æŒ‰é¡ºåºå°è¯•æ¯ä¸ªæ¨¡å‹
  for (const model of GEMINI_MODELS) {
    // æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ€è¿‘å¤±è´¥è¿‡å¤š
    const failureInfo = modelFailureTracker.get(model)
    if (failureInfo && failureInfo.count >= 3 && Date.now() - failureInfo.lastFailure < 300000) { // 5åˆ†é’Ÿå†·å´
      console.log(`ğŸš« Skipping model ${model} due to recent failures (${failureInfo.count} failures)`)
      continue
    }

    let modelAttempt = 0
    const maxModelAttempts = 3

    while (modelAttempt < maxModelAttempts) {
      let timeoutId: ReturnType<typeof setTimeout> | undefined
      try {
        console.log(`ğŸ¤– Trying Gemini model: ${model} (attempt ${modelAttempt + 1}/${maxModelAttempts})`)

        // API call with extended timeout for large batches
        const controller = new AbortController()
        timeoutId = setTimeout(() => controller.abort(), 300000) // 5 minute timeout (increased from 2 minutes)

        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${geminiApiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            contents: [{
              parts: [{
                text: `You are an expert product analyst specializing in user feedback analysis. You MUST return valid JSON without markdown formatting or additional text. Only return the JSON object with themes array. Do not include any explanatory text before or after the JSON.

IMPORTANT: Return no more than 30 themes even if you receive 100-200 input themes. Focus on the most significant and distinct themes.

${prompt}`
              }]
            }],
            generationConfig: {
              temperature: 0.1,
              maxOutputTokens: 4000, // å‡å°‘è¾“å‡ºtokenä»¥é¿å…è¶…é™
              topP: 0.8,
              topK: 40
            }
          }),
          signal: controller.signal
        })

        if (timeoutId) {
          clearTimeout(timeoutId)
        }

        // å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯
        if (response.status === 429) {
          const errorText = await response.text()
          console.warn(`âš ï¸ Rate limit hit for model ${model}: ${errorText}`)

          // å°è¯•ä»é”™è¯¯å“åº”ä¸­æå–é‡è¯•å»¶è¿Ÿ
          let retryDelay = 7000 // é»˜è®¤7ç§’
          try {
            const errorData = JSON.parse(errorText)
            if (errorData.error?.details) {
              const retryInfo = errorData.error.details.find((d: any) => d['@type']?.includes('RetryInfo'))
              if (retryInfo?.retryDelay) {
                const delayMatch = retryInfo.retryDelay.match(/(\d+)s/)
                if (delayMatch) {
                  retryDelay = parseInt(delayMatch[1]) * 1000
                }
              }
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å»¶è¿Ÿ
          }

          // è®¡ç®—é€€é¿å»¶è¿Ÿ
          const backoffDelay = calculateBackoffDelay(globalAttempt, retryDelay)
          console.log(`â³ Waiting ${backoffDelay}ms before retry...`)

          await new Promise(resolve => setTimeout(resolve, backoffDelay))
          modelAttempt++
          globalAttempt++
          continue
        }

        if (!response.ok) {
          const errorText = await response.text()
          const error = new Error(`Gemini API error for model ${model}: ${response.status} - ${errorText}`)
          console.warn(`âš ï¸ Model ${model} failed: ${error.message}`)

          // è®°å½•æ¨¡å‹å¤±è´¥
          const currentFailures = modelFailureTracker.get(model) || { count: 0, lastFailure: 0 }
          modelFailureTracker.set(model, {
            count: currentFailures.count + 1,
            lastFailure: Date.now()
          })

          lastError = error
          break // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        }

        const data = await response.json()
        const content = data.candidates?.[0]?.content?.parts?.[0]?.text

        if (!content) {
          const error = new Error(`No content in Gemini response for model ${model}`)
          console.warn(`âš ï¸ Model ${model} returned no content`)
          lastError = error
          break // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        }

        console.log(`âœ… Successfully used model: ${model}`)
        console.log('ğŸ” Raw Gemini response preview:', content.substring(0, 300) + '...')

        // é‡ç½®æ¨¡å‹å¤±è´¥è®¡æ•°å™¨ï¼ˆæˆåŠŸè·å¾—å“åº”ï¼‰
        modelFailureTracker.delete(model)

        // æ”¹è¿›çš„JSONè§£æé€»è¾‘
        try {
          const cleanContent = sanitizeJsonContent(content)
          console.log('ğŸ§¹ Cleaned content preview:', cleanContent.substring(0, 300) + '...')

          let result: any
          try {
            result = JSON.parse(cleanContent)
          } catch (firstParseError) {
            // å¦‚æœç¬¬ä¸€æ¬¡è§£æå¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†
            console.warn('ğŸ”§ First JSON parse failed, trying aggressive cleanup...')
            console.log('ğŸ” Full problematic content (first 500 chars):', content.substring(0, 500))

            let aggressiveClean = content.trim()

            // å¯»æ‰¾æœ€å¯èƒ½çš„JSONè¾¹ç•Œ
            const possibleStarts = ['{', '[']
            let bestStart = -1, bestEnd = -1

            for (const startChar of possibleStarts) {
              const start = aggressiveClean.indexOf(startChar)
              if (start !== -1) {
                const endChar = startChar === '{' ? '}' : ']'
                const end = aggressiveClean.lastIndexOf(endChar)
                if (end > start) {
                  bestStart = start
                  bestEnd = end
                  break
                }
              }
            }

            if (bestStart !== -1 && bestEnd !== -1) {
              aggressiveClean = aggressiveClean.slice(bestStart, bestEnd + 1)

              // åº”ç”¨ä¿®å¤å‡½æ•°
              aggressiveClean = fixCommonJsonIssues(aggressiveClean)

              try {
                result = JSON.parse(aggressiveClean)
              } catch (secondParseError) {
                // æœ€åå°è¯•ï¼šå®Œæˆæˆªæ–­çš„JSON
                console.warn('ğŸ”§ Second parse failed, attempting JSON completion...')
                const completedJson = attemptJsonCompletion(aggressiveClean)
                console.log('ğŸ”§ Completed JSON preview:', completedJson.substring(0, 300) + '...')
                result = JSON.parse(completedJson)
              }
            } else {
              throw firstParseError
            }
          }

          // ä¸¥æ ¼éªŒè¯ç»“æ„
          if (result.themes && Array.isArray(result.themes) && result.themes.length > 0) {
            // éªŒè¯æ¯ä¸ªthemeçš„ç»“æ„å¹¶è¿‡æ»¤æ— æ•ˆçš„
            const validThemes = result.themes.filter((theme: any) => {
              const isValid = theme.title &&
                             typeof theme.title === 'string' &&
                             theme.title.trim().length > 2 &&
                             theme.title.trim().length < 200 && // é¿å…è¿‡é•¿çš„æ ‡é¢˜
                             theme.description &&
                             typeof theme.description === 'string' &&
                             theme.description.trim().length > 10 &&
                             // ç¡®ä¿æ˜¯æœ‰æ„ä¹‰çš„ä¸»é¢˜æ ‡é¢˜ï¼Œä¸æ˜¯å•ä¸ªè¯æ±‡
                             theme.title.split(' ').length >= 2 &&
                             !theme.title.toLowerCase().match(/^(json|reddit|app|store|google|play|analysis|result|themes?|title|description|quotes|suggestions)$/i)

              if (!isValid) {
                console.warn(`ğŸš¨ Filtered invalid theme: "${theme.title}" (reason: ${
                  !theme.title ? 'no title' :
                  typeof theme.title !== 'string' ? 'title not string' :
                  theme.title.trim().length <= 2 ? 'title too short' :
                  theme.title.trim().length >= 200 ? 'title too long' :
                  !theme.description ? 'no description' :
                  typeof theme.description !== 'string' ? 'description not string' :
                  theme.description.trim().length <= 10 ? 'description too short' :
                  theme.title.split(' ').length < 2 ? 'single word title' :
                  'matches blacklisted words'
                })`)
              }
              return isValid
            })

            // é™åˆ¶è¾“å‡ºä¸»é¢˜æ•°é‡ï¼ˆç”¨æˆ·åå¥½ï¼šä¸è¶…è¿‡30ä¸ªä¸»é¢˜ï¼‰
            const limitedThemes = validThemes.slice(0, 30)

            if (limitedThemes.length > 0) {
              console.log(`âœ… Successfully parsed ${limitedThemes.length} valid themes with model ${model} (filtered from ${result.themes.length} total)`)
              return { themes: limitedThemes }
            } else {
              console.warn(`âš ï¸ No valid themes found after filtering for model ${model}`)
            }
          }

          const error = new Error(`Invalid or empty themes structure in response for model ${model}`)
          console.warn(`âš ï¸ Model ${model} returned invalid structure`)
          lastError = error
          break // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

        } catch (parseError) {
          console.error(`âŒ JSON parsing failed for model ${model}:`, parseError.message)
          console.log('ğŸ” Full problematic content (first 500 chars):', content.substring(0, 500))

          const error = new Error(`Gemini model ${model} returned invalid JSON format: ${parseError.message}. Content preview: ${content.substring(0, 200)}...`)
          lastError = error
          break // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        }

      } catch (error) {
        if (timeoutId) {
          clearTimeout(timeoutId)
        }

        if (error.name === 'AbortError') {
          const timeoutError = new Error(`Model ${model} timed out after 2 minutes`)
          console.warn(`âš ï¸ ${timeoutError.message}`)
          lastError = timeoutError
          break // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        }

        console.warn(`âš ï¸ Model ${model} failed with error:`, error.message)

        // è®°å½•æ¨¡å‹å¤±è´¥
        const currentFailures = modelFailureTracker.get(model) || { count: 0, lastFailure: 0 }
        modelFailureTracker.set(model, {
          count: currentFailures.count + 1,
          lastFailure: Date.now()
        })

        lastError = error

        // å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè·³å‡ºåˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹
        if (modelAttempt >= maxModelAttempts - 1) {
          break
        }
      }

      modelAttempt++
      if (modelAttempt < maxModelAttempts) {
        const delay = calculateBackoffDelay(modelAttempt - 1, 1000)
        console.log(`â³ Retrying model ${model} in ${delay}ms...`)
        await new Promise(resolve => setTimeout(resolve, delay))
      }
    }
  }

  // å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
  const failureReport = Array.from(modelFailureTracker.entries())
    .map(([model, info]) => `${model}: ${info.count} failures`)
    .join(', ')

  throw new Error(`All Gemini models failed after multiple attempts. Model failures: ${failureReport}. Last error: ${lastError?.message || 'Unknown error'}`)
}



// ç§»é™¤äº†æœ‰é—®é¢˜çš„extractThemesFromTextå‡½æ•°
// è¿™ä¸ªå‡½æ•°ä¼šæŠŠ"json"ã€"Reddit"ç­‰å•è¯é”™è¯¯è¯†åˆ«ä¸ºä¸»é¢˜æ ‡é¢˜
// é—®é¢˜å‡ºåœ¨è¿™ä¸ªæ¡ä»¶ï¼š(trimmed.length < 100 && !trimmed.includes('.'))
// å®ƒä¼šæŠŠä»»ä½•çŸ­äº100å­—ç¬¦ä¸”ä¸åŒ…å«å¥å·çš„æ–‡æœ¬éƒ½å½“ä½œä¸»é¢˜æ ‡é¢˜

async function logSystemMetric(
  supabaseClient: any, 
  metricName: string, 
  metricValue: number, 
  metricUnit: string, 
  tags: any = {}
) {
  try {
    await supabaseClient
      .from('system_metrics')
      .insert({
        metric_type: metricName,
        metric_value: metricValue,
        metric_unit: metricUnit,
        details: tags,
        created_at: new Date().toISOString()
      })
  } catch (error) {
    console.warn('Failed to log system metric:', error)
  }
} 