import { createClient } from 'npm:@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
}

// Reddit API configuration
const REDDIT_CLIENT_ID = Deno.env.get('REDDIT_CLIENT_ID')
const REDDIT_CLIENT_SECRET = Deno.env.get('REDDIT_CLIENT_SECRET')
const REDDIT_USER_AGENT = Deno.env.get('REDDIT_USER_AGENT') || 'ReviewInsight/1.0 by YourUsername'

interface ScrapeRequest {
  appName: string // ç”¨æˆ·é€‰æ‹©çš„åº”ç”¨åç§°ï¼ˆä»åº”ç”¨åˆ—è¡¨ä¸­é€‰æ‹©çš„å®Œæ•´åç§°ï¼‰
  userSearchTerm?: string // ğŸ†• ç”¨æˆ·åœ¨æœç´¢æ¡†è¾“å…¥çš„åŸå§‹å…³é”®è¯
  scrapingSessionId?: string
  maxPosts?: number
}

interface RedditPost {
  text: string
  title: string
  score: number
  date: string
  subreddit: string
  url: string
  author: string
  searchTerm?: string
  upvoteRatio?: number
  commentCount?: number
  postId?: string
  gilded?: number
  isStickied?: boolean
}

class RedditAPIClient {
  private accessToken: string | null = null
  private tokenExpiry: number = 0
  private rateLimitDelay = 1000 // 1 second between requests

  constructor() {
    if (!REDDIT_CLIENT_ID || !REDDIT_CLIENT_SECRET) {
      console.warn('âš ï¸ Reddit API credentials not configured. Reddit scraping will be limited.')
    }
  }

  private async delay(ms: number): Promise<void> {
    await new Promise(resolve => setTimeout(resolve, ms))
  }

  // è·å– Reddit API è®¿é—®ä»¤ç‰Œ
  async getAccessToken(): Promise<string | null> {
    if (!REDDIT_CLIENT_ID || !REDDIT_CLIENT_SECRET) {
      return null
    }

    // æ£€æŸ¥ç°æœ‰ä»¤ç‰Œæ˜¯å¦ä»ç„¶æœ‰æ•ˆ
    if (this.accessToken && Date.now() < this.tokenExpiry) {
      return this.accessToken
    }

    try {
      console.log('ğŸ” Obtaining Reddit API access token...')
      
      const credentials = btoa(`${REDDIT_CLIENT_ID}:${REDDIT_CLIENT_SECRET}`)
      
      const response = await fetch('https://www.reddit.com/api/v1/access_token', {
        method: 'POST',
        headers: {
          'Authorization': `Basic ${credentials}`,
          'Content-Type': 'application/x-www-form-urlencoded',
          'User-Agent': REDDIT_USER_AGENT
        },
        body: 'grant_type=client_credentials'
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`Token request failed: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      
      if (data.access_token) {
        this.accessToken = data.access_token
        this.tokenExpiry = Date.now() + (data.expires_in * 1000) - 60000 // å‡å»1åˆ†é’Ÿä½œä¸ºç¼“å†²
        console.log(`âœ… Reddit API token obtained, expires in ${data.expires_in} seconds`)
        return this.accessToken
      } else {
        throw new Error('No access token in response')
      }

    } catch (error) {
      console.error('âŒ Failed to obtain Reddit API token:', error.message)
      return null
    }
  }

  // ä½¿ç”¨ Reddit API æœç´¢
  async searchWithAPI(query: string, subreddit?: string, limit: number = 100): Promise<RedditPost[]> {
    const token = await this.getAccessToken()
    if (!token) {
      console.log('âš ï¸ No Reddit API token available, skipping API search')
      return []
    }

    try {
      let searchUrl = 'https://oauth.reddit.com/search'
      const params = new URLSearchParams({
        q: query,
        sort: 'relevance',
        t: 'year', // ğŸ†• é™åˆ¶åœ¨ä¸€å¹´å†…çš„å¸–å­
        limit: limit.toString(),
        type: 'link'
      })

      if (subreddit) {
        params.append('restrict_sr', 'true')
        searchUrl = `https://oauth.reddit.com/r/${subreddit}/search`
      }

      const fullUrl = `${searchUrl}?${params.toString()}`
      
      console.log(`ğŸ” Reddit API search: ${subreddit ? `r/${subreddit}` : 'all'} for "${query}"`)
      
      const response = await fetch(fullUrl, {
        headers: {
          'Authorization': `Bearer ${token}`,
          'User-Agent': REDDIT_USER_AGENT
        }
      })

      if (!response.ok) {
        if (response.status === 401) {
          // Token expired, clear it
          this.accessToken = null
          this.tokenExpiry = 0
        }
        throw new Error(`API search failed: ${response.status}`)
      }

      const data = await response.json()
      
      if (data?.data?.children) {
        const posts = this.parseRedditAPIData(data.data.children, query)
        console.log(`âœ… Reddit API found ${posts.length} posts`)
        return posts
      }

      return []

    } catch (error) {
      console.error(`âŒ Reddit API search error for "${query}":`, error.message)
      return []
    }
  }

  // è§£æ Reddit API æ•°æ®
  private parseRedditAPIData(children: any[], searchTerm: string): RedditPost[] {
    const posts: RedditPost[] = []

    for (const child of children) {
      try {
        const post = child.data
        if (!post) continue

        // è¿‡æ»¤æ‰è¢«åˆ é™¤æˆ–ç§»é™¤çš„å¸–å­
        if (post.removed_by_category || post.banned_by || 
            post.title === '[removed]' || post.title === '[deleted]') {
          continue
        }

        const title = post.title || ''
        const selftext = post.selftext || ''
        const content = selftext || title

        // æœ€å°å†…å®¹é•¿åº¦æ£€æŸ¥
        if (content.length < 20) continue

        posts.push({
          text: content,
          title: title,
          score: post.score || 0,
          date: new Date(post.created_utc * 1000).toISOString().split('T')[0],
          subreddit: post.subreddit || 'unknown',
          url: `https://reddit.com${post.permalink}`,
          author: post.author || 'Anonymous',
          searchTerm: searchTerm,
          upvoteRatio: post.upvote_ratio || 0,
          commentCount: post.num_comments || 0,
          postId: post.id || '',
          gilded: post.gilded || 0,
          isStickied: post.stickied || false
        })

      } catch (error) {
        console.error('Error parsing Reddit API post:', error)
        continue
      }
    }

    return posts
  }
}

class OptimizedRedditScraper {
  private apiClient: RedditAPIClient

  constructor() {
    this.apiClient = new RedditAPIClient()
  }

  // ğŸ†• ç®€åŒ–çš„å…³é”®è¯ç”Ÿæˆï¼šåªä½¿ç”¨æ ¸å¿ƒè¯æ±‡+ç‰¹å®šåç¼€
  private generateOptimizedSearchTerms(userSearchTerm?: string, appName?: string): string[] {
    const searchTerms = new Set<string>()
    
    console.log(`ğŸ”§ Generating simplified search terms - User: "${userSearchTerm || 'none'}", App: "${appName || 'none'}"`)
    
    // ç¡®å®šæ ¸å¿ƒæœç´¢è¯ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æœç´¢è¯ï¼Œå…¶æ¬¡æ˜¯åº”ç”¨åçš„æ ¸å¿ƒå…³é”®è¯
    let coreSearchTerm = ''
    
    if (userSearchTerm && userSearchTerm.trim().length > 0) {
      coreSearchTerm = userSearchTerm.trim().toLowerCase()
      console.log(`ğŸ¯ Using user search term as core: "${coreSearchTerm}"`)
    } else if (appName && appName.trim().length > 0) {
      // ä»åº”ç”¨åæå–ç¬¬ä¸€ä¸ªæ ¸å¿ƒå…³é”®è¯
      const appKeywords = this.extractSimpleAppKeywords(appName)
      if (appKeywords.length > 0) {
        coreSearchTerm = appKeywords[0]
        console.log(`ğŸ“± Using app keyword as core: "${coreSearchTerm}"`)
      }
    }
    
    // å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ ¸å¿ƒæœç´¢è¯ï¼Œè¿”å›ç©ºæ•°ç»„
    if (!coreSearchTerm || coreSearchTerm.length < 2) {
      console.log('âš ï¸ No valid core search term found')
      return []
    }
    
    // å®šä¹‰æœç´¢åç¼€ - æ‰©å±•ç‰ˆæœ¬
    const searchSuffixes = [
      // è¯„ä»·ç›¸å…³
      'review',
      'reviews',
      'rating',
      'ratings',
      'opinion',
      'opinions',
      'feedback',
      'thoughts',
      
      // å¹³å°ç›¸å…³
      'app',
      'application',
      'ios',
      'android',
      'mobile',
      'download',
      
      // é—®é¢˜ç›¸å…³
      'issue',
      'issues',
      'problem',
      'problems',
      'bug',
      'bugs',
      'error',
      'errors',
      'crash',
      'crashes',
      'glitch',
      'glitches',
      
      // ä½“éªŒç›¸å…³
      'experience',
      'experiences',
      'using',
      'tried',
      'testing',
      'working',
      'not working',
      'broken',
      'fixed',
      
      // æ¯”è¾ƒç›¸å…³
      'vs',
      'versus',
      'compared to',
      'alternative',
      'alternatives',
      'better than',
      'worse than',
      'similar to',
      
      // æ¨èç›¸å…³
      'recommend',
      'recommendation',
      'worth it',
      'good',
      'bad',
      'terrible',
      'awesome',
      'amazing',
      'disappointing',
      
      // åŠŸèƒ½ç›¸å…³
      'update',
      'updates',
      'new version',
      'latest version',
      'feature',
      'features',
      'settings',
      'setup',
      
      // ä½¿ç”¨ç›¸å…³
      'how to use',
      'tutorial',
      'guide',
      'tips',
      'tricks',
      'help'
    ]
    
    // ç”Ÿæˆæ ¸å¿ƒè¯æ±‡+åç¼€çš„ç»„åˆ
    for (const suffix of searchSuffixes) {
      searchTerms.add(`${coreSearchTerm} ${suffix}`)
    }
    
    // ä¹Ÿæ·»åŠ å•ç‹¬çš„æ ¸å¿ƒè¯æ±‡
    searchTerms.add(coreSearchTerm)
    searchTerms.add(`"${coreSearchTerm}"`) // ç²¾ç¡®åŒ¹é…
    
    // è½¬æ¢ä¸ºæ•°ç»„å¹¶è¿‡æ»¤
    const finalTerms = Array.from(searchTerms)
      .filter(term => {
        // åŸºæœ¬éªŒè¯
        if (!term || term.length < 3 || term.length > 40) return false
        if (term.includes('undefined') || term.includes('null')) return false
        
        // é¿å…åŒ…å«HTMLå®ä½“æˆ–ç‰¹æ®Šç¼–ç 
        if (term.includes('&amp;') || term.includes('&quot;')) return false
        
        return true
      })
      .slice(0, 25) // å¢åŠ åˆ°æœ€å¤š25ä¸ªæœç´¢è¯ä»¥è·å¾—æ›´å¤šè¦†ç›–

    console.log(`ğŸ“ Generated ${finalTerms.length} expanded search terms:`, finalTerms)
    return finalTerms
  }

  // ğŸ†• ä»åº”ç”¨åæå–ç®€å•å…³é”®è¯çš„è¾…åŠ©æ–¹æ³•
  private extractSimpleAppKeywords(appName: string): string[] {
    // æ¸…ç†åº”ç”¨åï¼šå»æ‰ç‰¹æ®Šå­—ç¬¦å’Œå¸¸è§åç¼€
    let cleanAppName = appName
      .toLowerCase()
      .replace(/[^\w\s]/g, ' ') // ç§»é™¤ç‰¹æ®Šå­—ç¬¦
      .replace(/\s+-\s+/g, ' ') // ç§»é™¤ " - "
      .replace(/\b(app|application|mobile|inc|llc|ltd|corp|company|&amp|amp)\b/gi, ' ') // ç§»é™¤å¸¸è§åç¼€
      .replace(/\s+/g, ' ') // åˆå¹¶å¤šä¸ªç©ºæ ¼
      .trim()
    
    console.log(`ğŸ”§ Cleaned app name: "${appName}" -> "${cleanAppName}"`)
    
    // æå–æœ‰æ„ä¹‰çš„è¯æ±‡
    const keywords = cleanAppName.split(/\s+/)
      .filter(word => word.length > 2)
      .filter(word => !['the', 'and', 'for', 'with', 'app', 'mobile', 'application', 'drive', 'deliver', 'driver'].includes(word.toLowerCase()))
      .slice(0, 3) // åªå–å‰3ä¸ªæœ€é‡è¦çš„è¯
    
    console.log(`ğŸ¯ Extracted app keywords:`, keywords)
    return keywords
  }

  // è·å–é‡ç‚¹ subredditsï¼ˆå¢å¼ºç‰ˆï¼‰
  private getTargetSubreddits(): string[] {
    return [
      // åº”ç”¨å’Œè½¯ä»¶ç›¸å…³ (é«˜ä¼˜å…ˆçº§)
      'apps', 'androidapps', 'iosapps', 'AppReviews', 'software', 'SoftwareRecommendations',
      'AppHookup', 'AppleWatch', 'iPhone', 'iPad', 'Android', 'GooglePlay', 'AppStore',
      
      // æŠ€æœ¯å’Œå¹³å°ç›¸å…³
      'technology', 'tech', 'TechSupport', 'TechReviews', 'gadgets', 'apple', 'google',
      'microsoft', 'opensource', 'Programming', 'webdev', 'MacApps', 'WindowsApps',
      
      // ç”Ÿäº§åŠ›å’Œå·¥ä½œç›¸å…³
      'productivity', 'ProductivityApps', 'WorkflowApps', 'studytips', 'LifeProTips',
      'GetStudying', 'organization', 'selfimprovement',
      
      // ç”¨æˆ·è®¨è®ºå’Œæ¨è
      'AskReddit', 'NoStupidQuestions', 'tipofmytongue', 'HelpMeFind', 'findareddit',
      'reviews', 'BuyItForLife', 'YouShouldKnow', 'LifeHacks',
      
      // æ¸¸æˆå’Œå¨±ä¹ç›¸å…³
      'gaming', 'AndroidGaming', 'iosGaming', 'GameReviews', 'MobileGaming',
      'indiegames', 'GameDeals', 'Steam',
      
      // ç¤¾äº¤å’Œé€šè®¯ç›¸å…³
      'socialmedia', 'privacy', 'security', 'Telegram', 'WhatsApp', 'Signal',
      'Instagram', 'Twitter', 'Facebook', 'TikTok', 'YouTube',
      
      // é‡‘èå’Œå•†åŠ¡ç›¸å…³
      'personalfinance', 'investing', 'CryptoCurrency', 'Entrepreneur', 'smallbusiness',
      'Banking', 'FinTech', 'ecommerce', 'startups',
      
      // è®¾è®¡å’Œåˆ›æ„
      'Design', 'GraphicDesign', 'UserExperience', 'UI_Design', 'web_design',
      'photography', 'AdobeIllustrator', 'photoshop',
      
      // å¥åº·å’Œç”Ÿæ´»æ–¹å¼
      'fitness', 'nutrition', 'loseit', 'getmotivated', 'selfcare',
      'meditation', 'sleep', 'running', 'bodyweightfitness'
    ]
  }

  // ğŸ†• ç®€åŒ–çš„åº”ç”¨ç‰¹å®šsubredditç”Ÿæˆ
  private generateAppSpecificSubreddits(userSearchTerm?: string, appName?: string): string[] {
    const appSubreddits: string[] = []
    
    console.log(`ğŸ¯ Generating simplified app-specific subreddits - User: "${userSearchTerm || 'none'}", App: "${appName || 'none'}"`)
    
    // ç¡®å®šæ ¸å¿ƒæœç´¢è¯ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æœç´¢è¯ï¼Œå…¶æ¬¡æ˜¯åº”ç”¨åçš„æ ¸å¿ƒå…³é”®è¯
    let coreSearchTerm = ''
    
    if (userSearchTerm && userSearchTerm.trim().length > 0) {
      coreSearchTerm = userSearchTerm.trim().toLowerCase()
        .replace(/[^\w\s]/g, '')
        .replace(/\s+/g, '')
      console.log(`ğŸ¯ Using user search term for subreddits: "${coreSearchTerm}"`)
    } else if (appName && appName.trim().length > 0) {
      const appKeywords = this.extractSimpleAppKeywords(appName)
      if (appKeywords.length > 0) {
        coreSearchTerm = appKeywords[0].replace(/[^\w\s]/g, '').replace(/\s+/g, '')
        console.log(`ğŸ“± Using app keyword for subreddits: "${coreSearchTerm}"`)
      }
    }
    
    // å¦‚æœæœ‰æœ‰æ•ˆçš„æ ¸å¿ƒæœç´¢è¯ï¼Œç”Ÿæˆå¯èƒ½çš„subredditåç§°
    if (coreSearchTerm && coreSearchTerm.length >= 3 && coreSearchTerm.length <= 15) {
      appSubreddits.push(coreSearchTerm)
      
      // åªå¯¹çŸ¥åå“ç‰Œæ·»åŠ æœ€ç›¸å…³çš„åç¼€
      const knownBrands = ['uber', 'lyft', 'doordash', 'grubhub', 'postmates', 'spotify', 'netflix', 'amazon', 'google', 'apple', 'microsoft']
      if (knownBrands.includes(coreSearchTerm)) {
        // åªæ·»åŠ æœ€å¸¸è§å’Œç›¸å…³çš„åç¼€
        if (['uber', 'lyft', 'doordash', 'grubhub', 'postmates'].includes(coreSearchTerm)) {
          appSubreddits.push(`${coreSearchTerm}driver`)
          appSubreddits.push(`${coreSearchTerm}drivers`)
        }
      }
    }
    
    // è¿‡æ»¤å¹¶è¿”å›åˆç†çš„subredditåç§°
    const uniqueSubreddits = [...new Set(appSubreddits)]
      .filter(sub => {
        // åŸºæœ¬æ ¼å¼æ£€æŸ¥
        if (sub.length < 3 || sub.length > 21) return false
        if (!/^[a-z0-9]+$/i.test(sub)) return false
        return true
      })
      .slice(0, 3) // åªä¿ç•™æœ€å¤š3ä¸ªç›¸å…³çš„subreddit

    console.log(`ğŸ¯ Generated ${uniqueSubreddits.length} simplified app-specific subreddits:`, uniqueSubreddits)
    return uniqueSubreddits
  }

  // ğŸš€ å¢å¼ºçš„ä¸»æœç´¢æ–¹æ³•ï¼šæ‰©å±•çš„ Reddit API ç­–ç•¥
  async scrapeReddit(userSearchTerm?: string, appName?: string, maxPosts: number = 400): Promise<RedditPost[]> {
    const allPosts: RedditPost[] = []
    
    console.log(`\nğŸš€ === ENHANCED REDDIT SCRAPER (EXPANDED API STRATEGY) ===`)
    console.log(`ğŸ‘¤ User search term: "${userSearchTerm || 'not provided'}"`)
    console.log(`ğŸ“± App name: "${appName || 'not provided'}"`)
    console.log(`ğŸ”‘ Reddit API: ${REDDIT_CLIENT_ID ? 'Configured' : 'Not configured'}`)
    console.log(`ğŸ“Š Target max posts: ${maxPosts}`)
    console.log(`â° Start Time: ${new Date().toISOString()}`)

    // æ£€æŸ¥APIå¯ç”¨æ€§
    if (!REDDIT_CLIENT_ID || !REDDIT_CLIENT_SECRET) {
      console.error('âŒ Reddit API credentials not configured. Cannot proceed with scraping.')
      return []
    }

    const searchTerms = this.generateOptimizedSearchTerms(userSearchTerm, appName)
    const generalSubreddits = this.getTargetSubreddits()
    const appSpecificSubreddits = this.generateAppSpecificSubreddits(userSearchTerm, appName)
    const allSubreddits = [...generalSubreddits, ...appSpecificSubreddits]

    console.log(`ğŸŒ Total search terms: ${searchTerms.length}`)
    console.log(`ğŸ“¡ General subreddits: ${generalSubreddits.length}`)
    console.log(`ğŸ¯ App-specific subreddits: ${appSpecificSubreddits.length}`)
    console.log(`ğŸ“Š Total subreddits to search: ${allSubreddits.length}`)

    try {
      // ç­–ç•¥1: æ‰©å±•çš„å…¨å±€æœç´¢ - æ›´å¤šå…³é”®è¯
      console.log(`\nğŸŒ === ENHANCED GLOBAL SEARCH ===`)
      for (const term of searchTerms.slice(0, 15)) { // å¢åŠ åˆ°15ä¸ªå…³é”®è¯
        console.log(`ğŸ” Global search for: "${term}"`)
        const apiPosts = await this.apiClient.searchWithAPI(term, undefined, 60) // å¢åŠ æ¯æ¬¡æœç´¢çš„æ•°é‡
        allPosts.push(...apiPosts)
        console.log(`âœ… Global search "${term}": ${apiPosts.length} posts`)
        await this.delay(1000)
      }

      // ç­–ç•¥2: é‡ç‚¹é€šç”¨ subreddit æœç´¢
      console.log(`\nğŸ“¡ === ENHANCED TARGETED SUBREDDIT SEARCH ===`)
      for (const subreddit of generalSubreddits.slice(0, 15)) { // å¢åŠ åˆ°15ä¸ªé€šç”¨subreddit
        for (const term of searchTerms.slice(0, 8)) { // æ¯ä¸ªsubredditæœç´¢8ä¸ªå…³é”®è¯
          console.log(`ğŸ” r/${subreddit} search for: "${term}"`)
          const subredditPosts = await this.apiClient.searchWithAPI(term, subreddit, 30)
          allPosts.push(...subredditPosts)
          console.log(`âœ… r/${subreddit} "${term}": ${subredditPosts.length} posts`)
          await this.delay(800) // ç¨å¾®å‡å°‘å»¶è¿Ÿä»¥æé«˜æ•ˆç‡
        }
      }

      // ç­–ç•¥3: åº”ç”¨ç‰¹å®š subreddit æœç´¢
      console.log(`\nğŸ¯ === APP-SPECIFIC SUBREDDIT SEARCH ===`)
      for (const appSubreddit of appSpecificSubreddits) {
        for (const term of searchTerms.slice(0, 6)) { // æ¯ä¸ªåº”ç”¨ç‰¹å®šsubredditæœç´¢6ä¸ªå…³é”®è¯
          console.log(`ğŸ” r/${appSubreddit} search for: "${term}"`)
          try {
            const appSpecificPosts = await this.apiClient.searchWithAPI(term, appSubreddit, 20)
            allPosts.push(...appSpecificPosts)
            console.log(`âœ… r/${appSubreddit} "${term}": ${appSpecificPosts.length} posts`)
          } catch (error) {
            // æŸäº›åº”ç”¨ç‰¹å®šçš„subredditå¯èƒ½ä¸å­˜åœ¨ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            console.log(`âš ï¸ r/${appSubreddit} not found or accessible`)
          }
          await this.delay(800)
        }
      }

      // ç­–ç•¥4: ç®€åŒ–çš„é«˜çº§æœç´¢æ¨¡å¼ - åªä½¿ç”¨æ ¸å¿ƒè¯æ±‡+é«˜ä»·å€¼åç¼€
      console.log(`\nğŸ”¬ === SIMPLIFIED ADVANCED SEARCH ===`)
      
      // ç¡®å®šæ ¸å¿ƒæœç´¢è¯
      let coreSearchTerm = ''
      if (userSearchTerm && userSearchTerm.trim().length > 0) {
        coreSearchTerm = userSearchTerm.trim().toLowerCase()
        console.log(`ğŸ¯ Using user search term for advanced patterns: "${coreSearchTerm}"`)
      } else if (appName && appName.trim().length > 0) {
        const appKeywords = this.extractSimpleAppKeywords(appName)
        if (appKeywords.length > 0) {
          coreSearchTerm = appKeywords[0]
          console.log(`ğŸ“± Using app keyword for advanced patterns: "${coreSearchTerm}"`)
        }
      }
      
      // å¦‚æœæœ‰æœ‰æ•ˆçš„æ ¸å¿ƒæœç´¢è¯ï¼Œåªæœç´¢æœ€é«˜ä»·å€¼çš„ç»„åˆ
      if (coreSearchTerm && coreSearchTerm.length > 2) {
        const highValueSuffixes = ['vs', 'alternative', 'better than']
        
        for (const suffix of highValueSuffixes) {
          const pattern = `${coreSearchTerm} ${suffix}`
          console.log(`ğŸ” High-value pattern search: "${pattern}"`)
          const patternPosts = await this.apiClient.searchWithAPI(pattern, undefined, 20)
          allPosts.push(...patternPosts)
          console.log(`âœ… High-value pattern "${pattern}": ${patternPosts.length} posts`)
          await this.delay(1000)
        }
      }

      console.log(`âœ… Enhanced Reddit API search completed: ${allPosts.length} posts collected`)

    } catch (error) {
      console.error('âŒ Enhanced Reddit API search failed:', error.message)
    }

    // ç®€å•å»é‡
    const uniquePosts = this.deduplicatePosts(allPosts)
    
    console.log(`\nğŸ¯ === ENHANCED REDDIT SCRAPING COMPLETED ===`)
    console.log(`ğŸ“Š Total posts collected: ${allPosts.length}`)
    console.log(`âœ¨ Final unique posts: ${uniquePosts.length}`)
    console.log(`ğŸ”‘ Enhanced API strategy used`)
    console.log(`ğŸŒ Global searches: ${Math.min(searchTerms.length, 10)}`)
    console.log(`ğŸ“¡ General subreddits searched: ${Math.min(generalSubreddits.length, 15)}`)
    console.log(`ğŸ¯ App-specific subreddits searched: ${appSpecificSubreddits.length}`)
    console.log(`ğŸ”¬ Advanced patterns searched: up to 6`)
    console.log(`â° End Time: ${new Date().toISOString()}`)
    
    return uniquePosts.slice(0, maxPosts) // é™åˆ¶æœ€ç»ˆæ•°é‡
  }

  private async delay(ms: number): Promise<void> {
    await new Promise(resolve => setTimeout(resolve, ms))
  }

  // ç®€å•å»é‡æ–¹æ³•
  private deduplicatePosts(posts: RedditPost[]): RedditPost[] {
    const seen = new Set<string>()
    const uniquePosts: RedditPost[] = []

    for (const post of posts) {
      // ä½¿ç”¨å¸–å­IDä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
      const key = post.postId || `${post.title}_${post.author}_${post.date}`
      
      if (!seen.has(key) && post.text.length > 20) {
        seen.add(key)
        uniquePosts.push(post)
      }
    }

    // æŒ‰ç›¸å…³æ€§å’Œåˆ†æ•°æ’åº
    return uniquePosts.sort((a, b) => {
      // ä¼˜å…ˆè€ƒè™‘åˆ†æ•°
      if (b.score !== a.score) return b.score - a.score
      // ç„¶åè€ƒè™‘è¯„è®ºæ•°é‡
      return (b.commentCount || 0) - (a.commentCount || 0)
    })
  }
}

// ä¸»å¤„ç†å‡½æ•°
Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    const { 
      appName, 
      userSearchTerm, // ğŸ†• æ¥æ”¶ç”¨æˆ·åŸå§‹æœç´¢è¯
      scrapingSessionId, 
      maxPosts = 400 
    }: ScrapeRequest = await req.json()

    // è‡³å°‘éœ€è¦ä¸€ä¸ªæœç´¢æ¡ä»¶
    if (!appName && !userSearchTerm) {
      return new Response(
        JSON.stringify({ error: 'Missing appName or userSearchTerm parameter' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    console.log(`ğŸš€ Optimized Reddit scraping started`)
    console.log(`ğŸ‘¤ User search term: "${userSearchTerm || 'not provided'}"`)
    console.log(`ğŸ“± App name: "${appName || 'not provided'}"`)
    console.log(`ğŸ”‘ Reddit API status: ${REDDIT_CLIENT_ID ? 'Configured' : 'Not configured'}`)
    console.log(`ğŸ“Š Target max posts: ${maxPosts}`)

    const scraper = new OptimizedRedditScraper()
    const posts = await scraper.scrapeReddit(userSearchTerm, appName, maxPosts)

    // ä¿å­˜åˆ°æ•°æ®åº“å¹¶æ›´æ–°scraperçŠ¶æ€
    if (scrapingSessionId) {
      try {
        console.log(`ğŸ’¾ Saving ${posts.length} posts to database...`)
        
        const supabaseClient = createClient(
          Deno.env.get('SUPABASE_URL') ?? '',
          Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
        )

        // æ›´æ–°scraperçŠ¶æ€ä¸ºrunning
        await supabaseClient
          .from('scraping_sessions')
          .update({
            reddit_scraper_status: 'running',
            reddit_started_at: new Date().toISOString()
          })
          .eq('id', scrapingSessionId)

        const postsToSave = posts.map(post => ({
          scraping_session_id: scrapingSessionId,
          platform: 'reddit' as const,
          review_text: post.text,
          rating: null,
          review_date: post.date,
          author_name: post.author,
          source_url: post.url,
          additional_data: {
            title: post.title,
            score: post.score,
            subreddit: post.subreddit,
            search_term: post.searchTerm,
            upvote_ratio: post.upvoteRatio,
            comment_count: post.commentCount,
            post_id: post.postId,
            gilded: post.gilded,
            is_stickied: post.isStickied,
            scraper_version: 'enhanced_api_v7.0',
            user_search_term: userSearchTerm, // ğŸ†• è®°å½•ç”¨æˆ·æœç´¢è¯
            app_name_used: appName, // ğŸ†• è®°å½•åº”ç”¨å
            search_strategy: 'user_term_priority_enhanced'
          }
        }))

        // åˆ†æ‰¹ä¿å­˜
        const batchSize = 50
        for (let i = 0; i < postsToSave.length; i += batchSize) {
          const batch = postsToSave.slice(i, i + batchSize)
          
          const { error: saveError } = await supabaseClient
            .from('scraped_reviews')
            .insert(batch)

          if (saveError) {
            console.error(`âŒ Database save error for batch ${Math.floor(i/batchSize) + 1}:`, saveError)
          } else {
            console.log(`âœ… Saved batch ${Math.floor(i/batchSize) + 1}: ${batch.length} posts`)
          }
        }

        console.log(`âœ… Successfully saved all ${postsToSave.length} Reddit posts to database`)

        // æ›´æ–°scraperçŠ¶æ€ä¸ºcompleted
        await supabaseClient
          .from('scraping_sessions')
          .update({
            reddit_scraper_status: 'completed',
            reddit_completed_at: new Date().toISOString(),
            reddit_posts: posts.length
          })
          .eq('id', scrapingSessionId)

        console.log(`âœ… Reddit scraper status updated to completed`)

      } catch (saveError) {
        console.error('âŒ Error saving Reddit posts to database:', saveError)

        // æ›´æ–°scraperçŠ¶æ€ä¸ºfailed
        try {
          const supabaseClient = createClient(
            Deno.env.get('SUPABASE_URL') ?? '',
            Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
          )
          
          await supabaseClient
            .from('scraping_sessions')
            .update({
              reddit_scraper_status: 'failed',
              reddit_completed_at: new Date().toISOString(),
              reddit_error_message: saveError.message
            })
            .eq('id', scrapingSessionId)
        } catch (updateError) {
          console.error('âŒ Failed to update scraper status:', updateError)
        }
      }
    }

    // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    const stats = {
      totalPosts: posts.length,
      targetMaxPosts: maxPosts,
      subreddits: [...new Set(posts.map(p => p.subreddit))],
      averageScore: posts.length > 0 ? Math.round(posts.reduce((sum, p) => sum + p.score, 0) / posts.length) : 0,
      dateRange: posts.length > 0 ? {
        earliest: Math.min(...posts.map(p => new Date(p.date).getTime())),
        latest: Math.max(...posts.map(p => new Date(p.date).getTime()))
      } : null,
      searchStrategy: {
        userSearchTerm: userSearchTerm || null,
        appNameUsed: appName || null,
        strategy: 'user_term_priority_enhanced_api'
      },
      apiUsed: REDDIT_CLIENT_ID ? true : false,
      gildedPosts: posts.filter(p => (p.gilded || 0) > 0).length
    }

    console.log(`\nğŸ“Š === OPTIMIZED REDDIT SCRAPING STATISTICS ===`)
    console.log(`âœ… Total posts: ${stats.totalPosts}`)
    console.log(`ğŸ¯ Target was: ${stats.targetMaxPosts}`)
    console.log(`ğŸ“ˆ Achievement rate: ${((stats.totalPosts / stats.targetMaxPosts) * 100).toFixed(1)}%`)
    console.log(`ğŸ“ˆ Average Reddit score: ${stats.averageScore}`)
    console.log(`ğŸ·ï¸ Subreddits found: ${stats.subreddits.length}`)
    console.log(`ğŸ”‘ Reddit API used: ${stats.apiUsed}`)
    console.log(`ğŸ† Gilded posts: ${stats.gildedPosts}`)

    return new Response(
      JSON.stringify({ 
        posts,
        stats,
        message: `Enhanced Reddit scraping completed: ${posts.length} posts found using expanded API strategy with user search term "${userSearchTerm || 'not provided'}" and app keywords from "${appName || 'not provided'}"`,
        timestamp: new Date().toISOString(),
        scraper_version: 'enhanced_api_v7.0',
        search_optimization: {
          user_term_priority: true,
          app_name_keywords: true,
          enhanced_api_strategy: true,
          app_specific_subreddits: true,
          advanced_search_patterns: true
        }
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )

  } catch (error) {
    console.error('âŒ Critical error in Optimized Reddit scraping:', error)
    return new Response(
      JSON.stringify({ 
        error: 'Failed to scrape Reddit',
        details: error.message,
        posts: [],
        stats: {
          totalPosts: 0,
          errorCount: 1,
          scraper_version: 'enhanced_api_v7.0'
        },
        timestamp: new Date().toISOString()
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})